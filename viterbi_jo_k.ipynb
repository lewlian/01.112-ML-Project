{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, \"C:/User/JSaw/Desktop/01.112/01.112-ML-Project\")\n",
    "\n",
    "import part3 as tr\n",
    "import part2 as em\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'B-NP': 47305, 'I-NP': 54591, 'B-VP': 18261, 'B-ADVP': 3565, 'B-ADJP': 1751, 'I-ADJP': 574, 'B-PP': 18387, 'O': 23872, 'B-SBAR': 1899, 'I-VP': 10159, 'I-ADVP': 363, 'B-PRT': 468, 'I-PP': 223, 'B-CONJP': 49, 'I-CONJP': 64, 'B-INTJ': 26, 'I-INTJ': 7, 'I-SBAR': 48, 'B-UCP': 1, 'I-UCP': 4, 'B-LST': 11})\n",
      "['B-NP', 'START', 'I-NP', 'B-VP', 'B-ADVP', 'B-ADJP', 'I-ADJP', 'B-PP', 'O', 'STOP', 'B-SBAR', 'I-VP', 'I-ADVP', 'B-PRT', 'I-PP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-LST']\n",
      "['B-NP', 'I-NP', 'B-VP', 'B-ADVP', 'B-ADJP', 'I-ADJP', 'B-PP', 'O', 'B-SBAR', 'I-VP', 'I-ADVP', 'B-PRT', 'I-PP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-LST']\n",
      "47305\n",
      "54591\n",
      "1\n",
      "I-NP\n"
     ]
    }
   ],
   "source": [
    "dataset = \"EN\"\n",
    "file_em = dataset+\"/train\"\n",
    "em_params, tagCount, w = em.emmissionWithSmoothing(open(file_em, \"r\", encoding=\"utf8\"), 3)\n",
    "\n",
    "tr_params = tr.transition(open(file_em, \"r\", encoding=\"utf8\"))\n",
    "tags = list(tr_params)\n",
    "\n",
    "\n",
    "print(tags)\n",
    "tags.remove(\"STOP\")\n",
    "tags.remove(\"START\")\n",
    "print(tags)\n",
    "filePath = dataset+\"/dev.in\"\n",
    "# tags.append('unknown')\n",
    "# print(tags)\n",
    "# index_unknown = tags.index('O')\n",
    "\n",
    "common = ''\n",
    "max_count = 0\n",
    "for k,v in tagCount.items():\n",
    "    if v > max_count:\n",
    "        print(v)\n",
    "        common = k\n",
    "        max_count = v\n",
    "index_unknown = tags.index(common)\n",
    "print(index_unknown)\n",
    "print(tags[index_unknown])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'X': 6, 'Y': 6, 'Z': 6})\n",
      "['X', 'START', 'Y', 'Z', 'STOP']\n",
      "['X', 'Y', 'Z']\n"
     ]
    }
   ],
   "source": [
    "dataset = \"HW\"\n",
    "file_em = dataset+\"/hwtrain.txt\"\n",
    "em_params, tagCount, w = em.emmissionWithSmoothing(open(file_em, \"r\", encoding=\"utf8\"), 3)\n",
    "\n",
    "tr_params = tr.transition(open(file_em, \"r\", encoding=\"utf8\"))\n",
    "tags = list(tr_params)\n",
    "\n",
    "\n",
    "print(tags)\n",
    "tags.remove(\"STOP\")\n",
    "tags.remove(\"START\")\n",
    "print(tags)\n",
    "filePath = dataset+\"/hwin.txt\"\n",
    "# tags.append('O')\n",
    "# print(tags)\n",
    "# index_unknown = tags.index('O')\n",
    "# print(index_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(tr_params['I-NP']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(em_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tag,tagdict in em_params.items():\n",
    "#     for word, value in tagdict.items():\n",
    "#         if word == 'roadways':\n",
    "#             print(tag, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a\\n', 'c\\n', 'a\\n']\n"
     ]
    }
   ],
   "source": [
    "file_list = (open(filePath, \"r\", encoding=\"utf8\")).readlines()\n",
    "sentences = [list(group) for k, group in groupby(file_list, lambda x: x == \"\\n\") if not k]\n",
    "asentence = sentences[1]\n",
    "print(asentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,2\n"
     ]
    }
   ],
   "source": [
    "ls = [1,2]\n",
    "string = \",\".join(str(elem) for elem in ls)\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[''], [''], ['']], [[''], [''], ['']], [[''], [''], ['']]]\n",
      "{(1, ''): -9.223372036854776e+18, (2, ''): -9.223372036854776e+18, (3, ''): -4.094344562222101}\n",
      "[((3, ''), -4.094344562222101), ((1, ''), -9.223372036854776e+18)]\n",
      "[[[''], [''], ['']], [['3', '1'], [''], ['']], [[''], [''], ['']]]\n",
      "{(1, ''): -3.80666248977032, (2, ''): -1.8446744073709552e+19, (3, ''): -3.401197381662156}\n",
      "[((3, ''), -3.401197381662156), ((1, ''), -3.80666248977032)]\n",
      "[[[''], [''], ['']], [['3', '1'], ['3', '1'], ['']], [[''], [''], ['']]]\n",
      "{(1, ''): -4.499809670330265, (2, ''): -9.223372036854776e+18, (3, ''): -9.223372036854776e+18}\n",
      "[((1, ''), -4.499809670330265), ((2, ''), -9.223372036854776e+18)]\n",
      "[[[''], [''], ['']], [['3', '1'], ['3', '1'], ['1', '2']], [[''], [''], ['']]]\n",
      "{(1, '3'): -9.223372036854776e+18, (1, '1'): -1.8446744073709552e+19, (2, '3'): -6.984716320118265, (2, '1'): -7.39018142822643, (3, '1'): -6.984716320118265, (3, '2'): -9.223372036854776e+18}\n",
      "[((2, '3'), -6.984716320118265), ((3, '1'), -6.984716320118265)]\n",
      "[[[''], [''], ['']], [['3', '1'], ['3', '1'], ['1', '2']], [['32', '13'], [''], ['']]]\n",
      "{(1, '3'): -5.886104031450157, (1, '1'): -9.223372036854776e+18, (2, '3'): -9.223372036854776e+18, (2, '1'): -9.223372036854776e+18, (3, '1'): -6.29156913955832, (3, '2'): -9.223372036854776e+18}\n",
      "[((1, '3'), -5.886104031450157), ((3, '1'), -6.29156913955832)]\n",
      "[[[''], [''], ['']], [['3', '1'], ['3', '1'], ['1', '2']], [['32', '13'], ['31', '13'], ['']]]\n",
      "{(1, '3'): -6.984716320118267, (1, '1'): -9.223372036854776e+18, (2, '3'): -6.984716320118265, (2, '1'): -7.39018142822643, (3, '1'): -9.223372036854776e+18, (3, '2'): -1.8446744073709552e+19}\n",
      "[((2, '3'), -6.984716320118265), ((1, '3'), -6.984716320118267)]\n",
      "[[[''], [''], ['']], [['3', '1'], ['3', '1'], ['1', '2']], [['32', '13'], ['31', '13'], ['32', '31']]]\n"
     ]
    }
   ],
   "source": [
    "best_k_paths,T,arg = inner_viterbi_k(asentence, em_params, tr_params, tags,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Z', 'X', 'Y'], ['X', 'Z', 'Y']]\n",
      "[[[-2.70805020110221], [-9.223372036854776e+18], [-2.302585092994046]], [[-4.094344562222101, -9.223372036854776e+18], [-3.401197381662156, -3.80666248977032], [-4.499809670330265, -9.223372036854776e+18]], [[-6.984716320118265, -6.984716320118265], [-5.886104031450157, -6.29156913955832], [-6.984716320118265, -6.984716320118267]]]\n",
      "arg\n",
      "[[[''], [''], ['']], [['3', '1'], ['3', '1'], ['1', '2']], [['32', '13'], ['31', '13'], ['32', '31']]]\n"
     ]
    }
   ],
   "source": [
    "print(best_k_paths)\n",
    "print(T)\n",
    "print('arg')\n",
    "print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[''], [''], ['']], [[''], [''], ['']], [[''], [''], ['']]]\n"
     ]
    }
   ],
   "source": [
    "arg = [[[\"\"] for i in range(3)] for j in range(3) ]\n",
    "print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_viterbi_k(sentence, em_params, tr_params, tags, k):\n",
    "#     words = file.readlines()\n",
    "#     words = [x for x in sentence if x != '\\n']\n",
    "    words = sentence\n",
    "    \n",
    "    # FORWARD\n",
    "    n = len(words)\n",
    "\n",
    "    T= [[[0] for i in range(len(tags))] for j in range(n) ]\n",
    "\n",
    "    arg = [[[\"\"] for i in range(len(tags))] for j in range(n) ]\n",
    "#     arg = [[[0]]*len(tags)]*n\n",
    "    print(arg)\n",
    "    \n",
    "    \n",
    "    # base case/ first layer\n",
    "    for u in range(len(tags)):\n",
    "        word = words[0].rstrip(\"\\n\")\n",
    "#         print(word)\n",
    "        try:\n",
    "            \n",
    "            a = tr_params[tags[u]][\"START\"]\n",
    "            b = em.getLikelihood(em_params, word, tags[u],w)\n",
    "\n",
    "            if b == 0:\n",
    "                nb = -sys.maxsize\n",
    "            else:\n",
    "                nb = np.log(b)\n",
    "                \n",
    "            T[0][u] = [np.log(a)+nb]\n",
    "\n",
    "        except KeyError:\n",
    "            \n",
    "            if b == 0:\n",
    "                nb = -sys.maxsize\n",
    "            else:\n",
    "                nb = np.log(b)\n",
    "            T[0][u] = [-sys.maxsize + nb]\n",
    "            \n",
    "        except TypeError:\n",
    "            print('base has TypeError')\n",
    "            T[0][u] = [-sys.maxsize]\n",
    "    \n",
    "#     print(T)\n",
    "    \n",
    "\n",
    "    for j in range(1, n):\n",
    "#         print(k)\n",
    "        word = words[j].rstrip(\"\\n\")\n",
    "#         print(word)\n",
    "        \n",
    "        for v in range(len(tags)):\n",
    "            dic = {}\n",
    "            \n",
    "            for u in range(len(tags)):  \n",
    "                for t in range(len(T[j-1][0])):\n",
    "                    try:\n",
    "                        pilog = T[j-1][u][t]\n",
    "\n",
    "                        a = tr_params[tags[v]][tags[u]]\n",
    "                        b = em.getLikelihood(em_params, word, tags[v], w)\n",
    "\n",
    "                        if b==0:\n",
    "                            nb = -sys.maxsize\n",
    "                        else:\n",
    "                            nb = np.log(b)\n",
    "\n",
    "                        value = pilog+np.log(a)+nb\n",
    "\n",
    "                    except KeyError:\n",
    "    #                     print('there was a KeyError')\n",
    "                        if b == 0:\n",
    "                            nb = -sys.maxsize\n",
    "                        else:\n",
    "                            nb = np.log(b)\n",
    "\n",
    "                        value = pilog - sys.maxsize + nb\n",
    "\n",
    "                    path = arg[j-1][u][t]\n",
    "                \n",
    "                    dic[(u+1,path)] = value\n",
    "            \n",
    "            print(dic)\n",
    "            kt = Counter(dic)\n",
    "            top_k = kt.most_common(k)\n",
    "            print(top_k)\n",
    "            top_k_prob = []\n",
    "            top_k_path = []\n",
    "            \n",
    "            for i in range(k):\n",
    "                top_k_prob.append(top_k[i][1])\n",
    "#                 print(j,i)\n",
    "#                 print(top_k[i][0][1])\n",
    "#                 print(type(top_k[i][0][1]))\n",
    "                prev_path = top_k[i][0][1]\n",
    "                new_path = prev_path + str(top_k[i][0][0])\n",
    "                top_k_path.append(new_path)\n",
    "                \n",
    "            T[j][v] = top_k_prob\n",
    "            arg[j][v] = top_k_path\n",
    "            print(arg)\n",
    "            \n",
    "\n",
    "    \n",
    "#     print('T\\n',T)\n",
    "#     print('arg\\n',arg)\n",
    "\n",
    "\n",
    "    #BACKWARD\n",
    "    index = [0]*n\n",
    "    y = [0]*n\n",
    "    \n",
    "    #last value\n",
    "    last_layer = T[n-1]\n",
    "    final_check = {}\n",
    "    for i in range(len(last_layer)):\n",
    "        for t in range(k):\n",
    "            pilog = last_layer[i][t]\n",
    "            try:\n",
    "                a = tr_params[\"STOP\"][tags[i]]\n",
    "                value = pilog + np.log(a)\n",
    "            except KeyError:\n",
    "                value = pilog - sys.maxsize\n",
    "                \n",
    "            final_check[(i,t)] = value\n",
    "    final = Counter(final_check)\n",
    "    top_final = final.most_common(k)\n",
    "#     print(top_final)\n",
    "    best_k_paths = []\n",
    "    for m in range(k):\n",
    "        i = top_final[m][0][0]\n",
    "        t = top_final[m][0][1]\n",
    "        prev_path = arg[n-1][i][t]\n",
    "        total_path = prev_path+str(i+1)\n",
    "        total_path_tags = []\n",
    "        for l in range(len(total_path)):\n",
    "            total_path_tags.append(tags[int(total_path[l])-1])\n",
    "        best_k_paths.append(total_path_tags)\n",
    "\n",
    "    return best_k_paths,T,arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inner_viterbi(sentence, em_params, tr_params, tags):\n",
    "# #     words = file.readlines()\n",
    "# #     words = [x for x in sentence if x != '\\n']\n",
    "#     words = sentence\n",
    "    \n",
    "#     # FORWARD\n",
    "#     n = len(words)\n",
    "\n",
    "#     T= [[0 for i in range(len(tags))] for j in range(n) ]\n",
    "\n",
    "#     arg = [[0 for i in range(len(tags))] for j in range(n) ]\n",
    "    \n",
    "# #     print(words)\n",
    "    \n",
    "#     # base case/ first layer\n",
    "#     for u in range(len(tags)):\n",
    "#         word = words[0].rstrip(\"\\n\")\n",
    "# #         print(word)\n",
    "#         try:\n",
    "# #             T[0][u] = np.log(tr_params[tags[u]][\"START\"]*em.getLikelihood(em_params, words[0], tags[u]))\n",
    "            \n",
    "#             a = tr_params[tags[u]][\"START\"]\n",
    "#             b = em.getLikelihood(em_params, word, tags[u],w)\n",
    "# #             print('viterbi base:',a,b)\n",
    "#             if a!= 0 and b!= 0:\n",
    "#                 T[0][u] = np.log(a*b)\n",
    "#             else:\n",
    "#                 T[0][u] = -sys.maxsize\n",
    "#         except KeyError:\n",
    "#             T[0][u] = -sys.maxsize\n",
    "#         except TypeError:\n",
    "#             T[0][u] = -sys.maxsize\n",
    "    \n",
    "# #     nif = np.log(0)\n",
    "#     for k in range(1, n):\n",
    "# #         print(k)\n",
    "#         word = words[k].rstrip(\"\\n\")\n",
    "# #         print(word)\n",
    "#         for v in range(len(tags)):\n",
    "#             find_max = []\n",
    "#             find_arg = []\n",
    "            \n",
    "#             for u in range(len(tags)):     \n",
    "#                 try:\n",
    "#                     pilog = T[k-1][u]\n",
    "#                     pi = np.exp(pilog)\n",
    "                    \n",
    "# #                     print(tags[v])\n",
    "# #                     print(tags[u])\n",
    "#                     a = tr_params[tags[v]][tags[u]]\n",
    "#                     b = em.getLikelihood(em_params, word, tags[v], w)\n",
    "# #                         alog = np.log(a)\n",
    "# #                         blog = np.log(b)\n",
    "# #                     print('viterbi:',a,b,tags[v])\n",
    "#                     if a!=0 and b!=0:\n",
    "                        \n",
    "# #                             print('Say yes T!')\n",
    "# #                         value = np.log(pi*a*b)\n",
    "# #                         arg_value = np.log(pi*a)\n",
    "#                         value = pilog+np.log(a)+np.log(b)\n",
    "#                         arg_value = pilog+np.log(a)\n",
    "#                     else:\n",
    "# #                         print('something is zero')\n",
    "# #                         if (a==0):\n",
    "# #                             print('KNN a IS ZERO LA')\n",
    "# #                             print('v:',tags[v])\n",
    "# #                             print('u:',tags[u])\n",
    "# #                         if (b==0):\n",
    "# #                             print('CCB b IS ZERO LA')\n",
    "# #                             print('v:',tags[v])\n",
    "# #                             print(k,word)\n",
    "                            \n",
    "# #                         print(pilog)\n",
    "# #                         print(a,b)\n",
    "#                         value = -sys.maxsize\n",
    "#                         arg_value= 0\n",
    "\n",
    "#                 except KeyError:\n",
    "# #                     print('there was a KeyError')\n",
    "#                     value = -sys.maxsize\n",
    "#                     arg_value = 0\n",
    "\n",
    "\n",
    "#                 find_max.append(value)\n",
    "\n",
    "#                 find_arg.append(arg_value)\n",
    "            \n",
    "#             tmax = -sys.maxsize\n",
    "#             for i in range(len(find_max)):\n",
    "#                 value = find_max[i]\n",
    "# #                 if value!=0:\n",
    "#                 if value>tmax:\n",
    "#                     tmax = value\n",
    "#             if tmax == -sys.maxsize:\n",
    "#                 T[k][v] = -sys.maxsize # when all value = 0\n",
    "#             else:\n",
    "#                 T[k][v] = tmax\n",
    "                \n",
    "#             argmax = -sys.maxsize\n",
    "#             for i in range(len(find_max)):\n",
    "#                 value = find_arg[i]\n",
    "#                 if value!=0:\n",
    "#                     if value>argmax:\n",
    "#                         argmax = value\n",
    "#             if argmax == -sys.maxsize:\n",
    "#                 arg[k][v] = 0 # when all arg_value = 0\n",
    "#             else:\n",
    "#                 arg[k][v] = find_arg.index(argmax)+1\n",
    "\n",
    "    \n",
    "# #     print('T\\n',T)\n",
    "# #     print('arg\\n',arg)\n",
    "#     #BACKWARD\n",
    "#     index = [0]*n\n",
    "#     y = [0]*n\n",
    "    \n",
    "#     #last value\n",
    "# #     print('last layer:',T[n-1])\n",
    "#     true_max = -sys.maxsize\n",
    "#     for m in range(len(T[n-1])):\n",
    "#         value = T[n-1][m]\n",
    "#         if value != 0:\n",
    "#             if value > true_max:\n",
    "#                 true_max = value\n",
    "#     if true_max == -sys.maxsize:\n",
    "#         print('OH NO LAST LAYER ALL ZEROS')\n",
    "#         index[n-1] = index_unknown\n",
    "#         y[n-1] = tags[index[n-1]]\n",
    "#     else:\n",
    "#         index[n-1] = T[n-1].index(true_max)+1\n",
    "#         y[n-1] = tags[T[n-1].index(true_max)]\n",
    "    \n",
    "#     #the rest of values using stored arg table\n",
    "#     for j in range(n-1,0,-1):\n",
    "# #         print('find rest of values:',j)\n",
    "# #         print(j-1,j,index[j])\n",
    "#         index[j-1] = arg[j][index[j]-1]\n",
    "# #         print('prev',index[j])\n",
    "# #         print('now',index[j-1])\n",
    "#         y[j-1] = tags[index[j-1]-1]\n",
    "# #     print(y)\n",
    "#     return y,T,arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(file, em_params, tr_params, tags):\n",
    "    file_list = file.readlines()\n",
    "    sentences = [list(group) for k, group in groupby(file_list, lambda x: x == \"\\n\") if not k]\n",
    "    total_y = []\n",
    "    for i in range(len(sentences)):\n",
    "        if i%10 == 0:\n",
    "            print(i)\n",
    "        sentence = sentences[i]\n",
    "        y,T,arg = inner_viterbi(sentence, em_params, tr_params, tags)\n",
    "#         y = cviterbi(em_params, tr_params,tags, sentence, w)\n",
    "        total_y += y\n",
    "        total_y += [0]\n",
    "    return total_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_file(inputFile, outputfile, y):\n",
    "    f = open(outputfile, 'w+', encoding=\"utf8\")\n",
    "\n",
    "    finput = open(inputFile, 'r', encoding=\"utf8\")\n",
    "    lines = finput.readlines()\n",
    "    print(len(lines))\n",
    "    print(len(y))\n",
    "    for i in range(len(lines)):\n",
    "        if (lines[i].rstrip() != \"\"):\n",
    "            word = lines[i].rstrip()\n",
    "            # print(word, y[i+1])\n",
    "            if (word == '\\n'):\n",
    "                f.write(word)\n",
    "            else:\n",
    "                f.write(word+\" \"+y[i]+\"\\n\")\n",
    "            \n",
    "        else:\n",
    "            f.write('\\n')\n",
    "    f.close()\n",
    "    print('Finished writing to File.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = (open(filePath, \"r\", encoding=\"utf8\")).readlines()\n",
    "sentences = [list(group) for k, group in groupby(file_list, lambda x: x == \"\\n\") if not k]\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = viterbi((open(filePath, \"r\", encoding=\"utf8\")), em_params, tr_params, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileout = dataset+\"/dev.p3nozero.out\"\n",
    "predictions_file(filePath, fileout, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
